{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da70a08-1895-4d1f-8f50-93e2134b2e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# design goals:\n",
    "#\n",
    "# - understandability\n",
    "# - modularity\n",
    "# - configurability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acd026f-65bd-4393-bb40-f8aa8bd6828b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "WORKSPACE_NAME = \"default\"\n",
    "\n",
    "WORKSPACE_ROOT = Path(\"workspaces\")\n",
    "WORKSPACE_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "WORKSPACE_DIR = WORKSPACE_ROOT / WORKSPACE_NAME\n",
    "WORKSPACE_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SOURCE_DOCUMENT = None # to process a specific document, set its path here; otherwise, the entire source documents repository will be used\n",
    "SOURCE_DOCUMENT_DIR = WORKSPACE_DIR / \"source_documents\"\n",
    "\n",
    "CONVERSION_OUTPUT_DIR = WORKSPACE_DIR / \"conversion\"\n",
    "CONVERSION_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CHUNKING_OUTPUT_DIR = WORKSPACE_DIR / \"chunking\"\n",
    "CHUNKING_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "AUTHORING_OUTPUT_DIR = WORKSPACE_DIR / \"authoring\"\n",
    "AUTHORING_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SEED_EXAMPLE_OUTPUT_DIR = WORKSPACE_DIR / \"seed-examples\"\n",
    "SEED_EXAMPLE_OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "SDG_OUTPUT_DIR = WORKSPACE_DIR / \"sdg\"\n",
    "SDG_OUTPUT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b7ac5-fc2a-40a8-8e1f-e8dd8b1153e7",
   "metadata": {},
   "source": [
    "# Document Conversion\n",
    "\n",
    "This notebook uses [Docling](https://github.com/docling-project/docling) to convert any type of document into a Docling Document. A Docling Document is the representation of the document after conversion that can be exported as JSON. The JSON output of this notebook can then be used in others such as one that uses Docling's chunking methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91d4b2e-19cd-46e7-a912-ba9b2904c7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3804ef-4961-44b1-91c9-62929f422702",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "\n",
    "if SOURCE_DOCUMENT:\n",
    "    files.append(Path(SOURCE_DOCUMENT))\n",
    "else:\n",
    "    print(\"***** WARNING! Only one file at a time is supported at this time.\")\n",
    "    files = list(SOURCE_DOCUMENT_DIR.rglob(\"*.pdf\"))\n",
    "    print(f\"***** Using {files[0]})\")\n",
    "\n",
    "print(f\"Files to convert: {files}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fb64b-d089-4844-9330-7f3639819e7a",
   "metadata": {},
   "source": [
    "Next we set the configuration options for our conversion pipeline. The PDF Conversion options set here are the defaults. More information about pipeline configuration can be found on Docling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157c5e02-edd1-44f6-b20f-f6b4bda1aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "\n",
    "pipeline_options = PdfPipelineOptions() # TODO: show the options that can be set\n",
    "\n",
    "doc_converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options\n",
    "        )\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73400c74-dead-4998-aee2-ddb00ddaa276",
   "metadata": {},
   "source": [
    "Finally, we convert every document into Docling JSON as long as it is a valid file type to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200039c-b8b2-4087-88ba-7bfb0e393cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "for file in files:\n",
    "    doc = doc_converter.convert(source=file).document\n",
    "    doc_dict = doc.export_to_dict()\n",
    "\n",
    "    json_output_path = CONVERSION_OUTPUT_DIR / f\"{file.stem}.json\"\n",
    "    with open(json_output_path, \"w\") as f:\n",
    "        json.dump(doc_dict, f)\n",
    "        print(f\"Path of JSON output is: {Path(json_output_path).resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafad55e-a4c0-4d6e-9da0-49519fa9bf74",
   "metadata": {},
   "source": [
    "## Chunking\n",
    "\n",
    "The goal of chunking the converted documents is to provide the teacher model small and logical pieces of the source document to generate data off of.\n",
    "\n",
    "In this notebook we are doing chunking with [Docling](https://docling-project.github.io/docling/examples/hybrid_chunking/#hybrid-chunking).\n",
    "\n",
    "The input to this notebook is a docling JSON file created after a docling conversion, or a directory of docling JSON files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482060c-a49f-4345-aa47-d54301939387",
   "metadata": {},
   "source": [
    "## Initialize the Chunker\n",
    "\n",
    "Docling provides two chunkers, the `HierarchicalChunker` and the `HybridChunker`.\n",
    "The `HierarchicalChunker` creates chunks based on the hierarchy in the Docling document\n",
    "\n",
    "The `HybridChunker` builds on the `HierarchicalChunker` and by making it tokenization aware.\n",
    "\n",
    "The `HybridChunker` has options for a `tokenizer`, the `max_tokens` in a chunk, and whether to merge undersized peer chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50df9d91-add4-46a1-a69d-0f7f9f69542e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.chunking import HybridChunker\n",
    "\n",
    "chunker = HybridChunker() # TODO: expose configuration options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ce1d6f-b8d3-470c-b3c9-675911f0ee92",
   "metadata": {},
   "source": [
    "## Load and chunk the converted docling document\n",
    "\n",
    "Next lets convert the document we want to chunk up into a Docling Document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db983c05-4aa6-4261-9283-2adab69bfbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "docs = []\n",
    "for file in files:\n",
    "    doc = DocumentConverter().convert(source=file)\n",
    "    docs.append(doc)\n",
    "    \n",
    "    chunk_iter = chunker.chunk(dl_doc=doc.document)\n",
    "    chunk_objs = list(chunk_iter)\n",
    "    chunks = [chunker.serialize(chunk=chunk) for chunk in chunk_objs]\n",
    "\n",
    "    print(f\"Extracted {len(chunks)} chunks from {document.name}\")\n",
    "    \n",
    "    for chunk in chunks:\n",
    "        c = dict(chunk=chunk, file=file.stem)\n",
    "        all_chunks.append(c)\n",
    "\n",
    "# TODO: save all chunks to single file for review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb38545-eb84-4923-8fc4-d10ed08eab26",
   "metadata": {},
   "source": [
    "## View the Chunks\n",
    "\n",
    "To view the chunks, run through the following cell. As you can see the document is broken into small pieces with metadata about the chunk based on the document's format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdf34c7-9829-43d2-bf9f-7d1d55bb6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all_chunks)\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c4160f-7508-4c72-b28d-b56aa4975b26",
   "metadata": {},
   "source": [
    "## Save the chunks to a text file for each chunk\n",
    "\n",
    "Each chunk is saved to an individual text file in the format: `{docling-json-file-name}-{chunk #}.txt`. Having chunking in this format is important as an input to create-sdg-seed-data notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70d576-a2bc-4274-b660-1cbe051968b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(all_chunks):\n",
    "    chunk_path = CHUNKING_OUTPUT_DIR / f\"{chunk['file']}-{i}.txt\"\n",
    "    with open(chunk_path, \"w\") as file:\n",
    "        file.write(chunk[\"chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a510f8c7-8cd3-4867-8742-9f4f9cda9e9f",
   "metadata": {},
   "source": [
    "# Authoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c48e52-cda7-48ac-84dc-0b844aed5f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq docling-sdg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a165c38-843b-4c89-a8ad-6195b998e284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_sdg.qa.utils import get_qa_chunks\n",
    "\n",
    "filters = [\n",
    "    lambda chunk: len(str(chunk.text)) > 500\n",
    "]\n",
    "\n",
    "dataset = {}\n",
    "for doc in docs:\n",
    "    print(f\"Chunking and filtering document {doc.document.name}\")\n",
    "\n",
    "    chunks = list(chunker.chunk(dl_doc=doc.document))\n",
    "    qa_chunks = list(get_qa_chunks(doc.document.name, chunk_objs, filters)) #TODO: decouple reference to chunk_objs from above)\n",
    "    dataset[doc.document.name] = qa_chunks\n",
    "    \n",
    "    print(f\"Created dataset {doc.document.name} with {len(qa_chunks)} QA chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65ec755-e3de-40ab-bf3a-23ebb29a705d",
   "metadata": {},
   "source": [
    "## Initialize QA generator, supplying details for which model to use\n",
    "\n",
    "GenerateOptions controls which model is used for QA generation by setting generate_options.provider below. Three options are available:\n",
    "\n",
    "* LlmProviders.WATSONX for watsonx\n",
    "* LlmProviders.OPENAI for OpenAI\n",
    "* LlmProviders.OPENAI_LIKE for any model provider with OpenAI compatible APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702267e-f550-4bc2-bce4-c0fcecbbd292",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling_sdg.qa.generate import Generator\n",
    "from docling_sdg.qa.base import GenerateOptions, LlmProvider\n",
    "from pydantic import SecretStr\n",
    "\n",
    "generate_options = GenerateOptions(api_key=\"fake\", project_id=\"project_id\")\n",
    "generate_options.provider = LlmProvider.OPENAI_LIKE\n",
    "generate_options.api_key = SecretStr(\"fake\")\n",
    "generate_options.model_id = \"granite3.3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919199c0-3747-409a-85ab-0155ef3ebe9d",
   "metadata": {},
   "source": [
    "## Configure subset selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1197d4e-8354-45e3-9ec9-85c78ba36548",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CHUNKS_TO_SELECT_FOR_AUTHORING = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2421d07-3e6c-4355-95f4-da8e157557c7",
   "metadata": {},
   "source": [
    "## Run QA generation on selected chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57edff5-9a13-47fb-9248-9140ae5baaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random #TODO: replace random sampling with subset selection\n",
    "\n",
    "gen = Generator(generate_options=generate_options)\n",
    "for doc, chunks in dataset.items():\n",
    "    generate_options.generated_file = AUTHORING_OUTPUT_DIR / f\"qagen-{doc}.json\"\n",
    "    \n",
    "    print(f\"processing chunks that looks like:\\n{chunks[0].text}\")\n",
    "    selected_chunks = random.sample(chunks, NUM_CHUNKS_TO_SELECT_FOR_AUTHORING)\n",
    "    print(f\"Selected {len(selected_chunks)} contexts\")\n",
    "    \n",
    "    results = gen.generate_from_chunks(selected_chunks) # automatically saves to file\n",
    "    \n",
    "    print(f\"{doc}: {results.status}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea64b8f0-dd6c-4776-8646-9731433f909b",
   "metadata": {},
   "source": [
    "## Read generated QAs and restructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2c533-30d7-4c30-9907-7c5655fd2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import yaml\n",
    "from textwrap import wrap\n",
    "\n",
    "qnas = {}\n",
    "chunk_id_to_text = {}\n",
    "with open(generate_options.generated_file, \"rt\") as f:\n",
    "    for line in f.readlines():\n",
    "        entry = json.loads(line)\n",
    "        chunk_id = entry['chunk_id']\n",
    "        if chunk_id not in chunk_id_to_text:\n",
    "            chunk_id_to_text[chunk_id] = entry['context']\n",
    "        if chunk_id not in qnas:\n",
    "            qnas[chunk_id] = []\n",
    "        qnas[chunk_id].append({'question': entry['question'], 'answer': entry['answer']})\n",
    "\n",
    "print(list(qnas.values())[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafa8927-e56c-448b-b88b-f8d854c25d4d",
   "metadata": {},
   "source": [
    "## Output qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f26460-737f-4940-b58a-ef6caea313d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qna_output_path = AUTHORING_OUTPUT_DIR / Path(generate_options.generated_file.stem)\n",
    "\n",
    "def str_presenter(dumper, data):\n",
    "  if len(data.splitlines()) > 1:  # check for multiline string\n",
    "    return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n",
    "  elif len(data) > 80:\n",
    "    data = \"\\n\".join(wrap(data, 80))\n",
    "    return dumper.represent_scalar('tag:yaml.org,2002:str', data, style='|')\n",
    "  return dumper.represent_scalar('tag:yaml.org,2002:str', data)\n",
    "\n",
    "yaml.add_representer(str, str_presenter)\n",
    "\n",
    "# to use with safe_dump:\n",
    "yaml.representer.SafeRepresenter.add_representer(str, str_presenter)\n",
    "\n",
    "class IndentedDumper(yaml.Dumper):\n",
    "    def increase_indent(self, flow=False, indentless=False):\n",
    "        return super(IndentedDumper, self).increase_indent(flow, False)\n",
    "\n",
    "data = {'seed_examples': []}\n",
    "for chunk_id, context in chunk_id_to_text.items():\n",
    "    data['seed_examples'].append({\n",
    "        'context': context,\n",
    "        'questions_and_answers': [\n",
    "            {\n",
    "                'question': example['question'],\n",
    "                'answer': example['answer'],\n",
    "            } for example in qnas[chunk_id]\n",
    "        ]\n",
    "    })\n",
    "\n",
    "with open(qna_output_path, 'w') as yaml_file:\n",
    "    yaml.dump(data, yaml_file, Dumper=IndentedDumper, default_flow_style=False, sort_keys=False, width=80)\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d17d8-b9da-482d-9594-ef1ae81f108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## View generated qna.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1293d445-b826-4b92-ad20-9b121ac60e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(qna_output_path) as yaml_file:\n",
    "    print(yaml_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149dbbf-5601-4aa5-b1e9-e454ea0a4529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
